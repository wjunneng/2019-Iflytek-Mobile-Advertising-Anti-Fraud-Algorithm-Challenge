{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "testdata_feature.columns:  Index(['sid', 'pkgname', 'ver', 'adunitshowid', 'mediashowid', 'apptype',\n       'nginxtime', 'ip', 'city', 'province', 'reqrealip', 'adidmd5',\n       'imeimd5', 'idfamd5', 'openudidmd5', 'macmd5', 'dvctype', 'model',\n       'make', 'ntt', 'carrier', 'os', 'osv', 'orientation', 'lan', 'h', 'w',\n       'ppi'],\n      dtype='object')\ntraindata.columns:  Index(['sid', 'label', 'pkgname', 'ver', 'adunitshowid', 'mediashowid',\n       'apptype', 'nginxtime', 'ip', 'city', 'province', 'reqrealip',\n       'adidmd5', 'imeimd5', 'idfamd5', 'openudidmd5', 'macmd5', 'dvctype',\n       'model', 'make', 'ntt', 'carrier', 'os', 'osv', 'orientation', 'lan',\n       'h', 'w', 'ppi'],\n      dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "# 项目路径\n",
    "project_path = '/home/wjunneng/Python/2019-Iflytek-Mobile-Advertising-Anti-Fraud-Algorithm-Challenge'\n",
    "# round1_iflyad_anticheat_testdata_feature.txt文件路径\n",
    "testdata_feature_path = project_path + '/data/original/round1_iflyad_anticheat_testdata_feature.txt'\n",
    "# round1_iflyad_anticheat_traindata.txt文件路径\n",
    "traindata_path = project_path + '/data/original/round1_iflyad_anticheat_traindata.txt'\n",
    "\n",
    "\n",
    "def one_hot_col(col):\n",
    "    \"\"\"标签编码\"\"\"\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(col)\n",
    "    return lbl\n",
    "\n",
    "\n",
    "def calculate_null(data, key, col):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    data -- input data\n",
    "    key -- the key used for statistics\n",
    "    col -- the columns for statistics\n",
    "    return -- the data of DataFrame type, include two columns,\n",
    "              first columns id key,second is number of null\n",
    "    \"\"\"\n",
    "    return data.groupby(key, as_index=False)[col].agg({col + '_is_null': 'count'})\n",
    "\n",
    "\n",
    "def xgb_model(new_train, y, new_test, lr):\n",
    "    \"\"\"定义模型\"\"\"\n",
    "    xgb_params = {'booster': 'gbtree',\n",
    "                  'eta': lr, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "                  'objective': 'binary:logistic',\n",
    "                  'eval_metric': 'auc',\n",
    "                  'silent': True,\n",
    "                  }\n",
    "    # skf=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=2018)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    oof_xgb = np.zeros(new_train.shape[0])\n",
    "    prediction_xgb = np.zeros(new_test.shape[0])\n",
    "    for i, (tr, va) in enumerate(skf.split(new_train, y)):\n",
    "        print('fold:', i + 1, 'training')\n",
    "        dtrain = xgb.DMatrix(new_train[tr], y[tr])\n",
    "        dvalid = xgb.DMatrix(new_train[va], y[va])\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid_data')]\n",
    "        bst = xgb.train(dtrain=dtrain, num_boost_round=30000, evals=watchlist, early_stopping_rounds=200,\n",
    "                        verbose_eval=50, params=xgb_params)\n",
    "        oof_xgb[va] += bst.predict(xgb.DMatrix(new_train[va]), ntree_limit=bst.best_ntree_limit)\n",
    "        prediction_xgb += bst.predict(xgb.DMatrix(new_test), ntree_limit=bst.best_ntree_limit)\n",
    "    print('the roc_auc_score for train:', roc_auc_score(y, oof_xgb))\n",
    "    prediction_xgb /= 5\n",
    "    return oof_xgb, prediction_xgb\n",
    "\n",
    "\n",
    "def lgb_model(new_train, y, new_test):\n",
    "    params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'num_leaves': 1000,\n",
    "        'verbose': -1,\n",
    "        'max_depth': -1,\n",
    "        #  'reg_alpha':2.2,\n",
    "        #  'reg_lambda':1.4,\n",
    "        'seed': 42,\n",
    "    }\n",
    "    # skf=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=2018)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    oof_lgb = np.zeros(new_train.shape[0])  # 用于存放训练集概率，由每折验证集所得\n",
    "    prediction_lgb = np.zeros(new_test.shape[0])  # 用于存放测试集概率，k折最后要除以k取平均\n",
    "    feature_importance_df = pd.DataFrame()  # 存放特征重要性，此处不考虑\n",
    "    for i, (tr, va) in enumerate(skf.split(new_train, y)):\n",
    "        print('fold:', i + 1, 'training')\n",
    "        dtrain = lgb.Dataset(new_train[tr], y[tr])\n",
    "        dvalid = lgb.Dataset(new_train[va], y[va], reference=dtrain)\n",
    "        # 训练：\n",
    "        bst = lgb.train(params, dtrain, num_boost_round=30000, valid_sets=dvalid, verbose_eval=400,\n",
    "                        early_stopping_rounds=200)\n",
    "        # 预测验证集：\n",
    "        oof_lgb[va] += bst.predict(new_train[va], num_iteration=bst.best_iteration)\n",
    "        # 预测测试集：\n",
    "        prediction_lgb += bst.predict(new_test, num_iteration=bst.best_iteration)\n",
    "        \"\"\"\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = list(new_train.columns)\n",
    "        fold_importance_df[\"importance\"] = bst.feature_importance(importance_type='split', iteration=bst.best_iteration)\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \"\"\"\n",
    "\n",
    "    print('the roc_auc_score for train:', roc_auc_score(y, oof_lgb))  # 线下auc评分\n",
    "    prediction_lgb /= 5\n",
    "    return oof_lgb, prediction_lgb, feature_importance_df\n",
    "\n",
    "\n",
    "def get_testdata_feature(**params):\n",
    "    \"\"\"\n",
    "    返回 testdata_feature 文件内容\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    testdata_feature_data = pd.read_table(testdata_feature_path, sep='\\t')\n",
    "\n",
    "    return testdata_feature_data\n",
    "\n",
    "\n",
    "def get_traindata(**params):\n",
    "    \"\"\"\n",
    "    返回 traindata 文件内容\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    traindata_data = pd.read_table(traindata_path, sep='\\t')\n",
    "\n",
    "    return traindata_data\n",
    "\n",
    "\n",
    "testdata_feature = get_testdata_feature()\n",
    "traindata = get_traindata()\n",
    "\n",
    "print('testdata_feature.columns: ', testdata_feature.columns)\n",
    "print('traindata.columns: ', traindata.columns)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "traindata.shape: \n (1000000, 31)\n\n\ntestdata_feature.shape:  (100000, 31)\n\n\n",
      "the shape of data: \n (1100000, 31)\n\n\n",
      "data.nunique(): \n sid                    1100000\nlabel                        3\npkgname                   2368\nver                       3268\nadunitshowid               800\nmediashowid                313\napptype                     91\nnginxtime              1098977\nip                      813719\ncity                       331\nprovince                     8\nreqrealip                 9748\nadidmd5                 780369\nimeimd5                1021836\nidfamd5                    360\nopenudidmd5              85051\nmacmd5                  329184\ndvctype                      3\nmodel                     7957\nmake                      2727\nntt                          8\ncarrier                      5\nos                           2\nosv                        185\norientation                  4\nlan                         33\nh                          985\nw                          449\nppi                        119\nbegintime              1099019\nnginxtime-begintime        674\ndtype: int64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def conversion_time(df, column, **params):\n",
    "    \"\"\"\n",
    "    对会话开始和结束时间进行标准化\n",
    "    :param df:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 本题所给时间戳为毫秒级，故需除以1000转换为秒级：时间戳转成日期格式\n",
    "    df[column] = df[column].apply(lambda x: time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(int(int(x)/1000))))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 读入测试数据：\n",
    "testdata_feature['label'] = -1  # 测试集没有标签，可标记为-1\n",
    "\n",
    "# 请求会话时间\n",
    "testdata_feature['begintime'] = testdata_feature['sid'].apply(lambda x: int(x.split('-')[-1]))  \n",
    "# 请求会话时间 与 请求到达服务时间的差\n",
    "testdata_feature['nginxtime-begintime'] = testdata_feature['nginxtime'] - testdata_feature['begintime']  \n",
    "\n",
    "# 请求会话时间\n",
    "traindata['begintime'] = traindata['sid'].apply(lambda x: int(x.split('-')[-1]))\n",
    "# 请求会话时间 与 请求到达服务时间的差\n",
    "traindata['nginxtime-begintime'] = traindata['nginxtime'] - traindata['begintime']\n",
    "\n",
    "\n",
    "print('traindata.shape: \\n', traindata.shape)\n",
    "print('\\n')\n",
    "print('testdata_feature.shape: ', testdata_feature.shape)\n",
    "print('\\n')\n",
    "\n",
    "# 结合数据，方便提取特征：axis=0 纵向合并；axis=1 横向合并\n",
    "data = pd.concat([traindata, testdata_feature], axis=0, sort=False).reset_index(drop=True)\n",
    "\n",
    "print('the shape of data: \\n', data.shape)\n",
    "print('\\n')\n",
    "print('data.nunique(): \\n', data.nunique())  # 返回每个字段的所有值组成集合的大小，即集合元素个数\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "label distribution:\n 0    517106\n1    482894\nName: label, dtype: int64\n\n\nobject_cols:\n ['sid', 'pkgname', 'ver', 'adunitshowid', 'mediashowid', 'ip', 'city', 'reqrealip', 'adidmd5', 'imeimd5', 'idfamd5', 'openudidmd5', 'macmd5', 'model', 'make', 'os', 'osv', 'lan']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "z = calculate_null(testdata_feature, 'sid', 'ver')  # 计算缺失值的，下面还没用到\n",
    "\n",
    "print('label distribution:\\n', traindata['label'].value_counts())  # 查看训练集标签分布\n",
    "print('\\n')\n",
    "object_cols = list(data.dtypes[data.dtypes == np.object].index)  # 返回字段名为object类型的字段\n",
    "print('object_cols:\\n', object_cols)  # 输出object类型的字段\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2019-06-09 22:31:41\n",
      "0          1.560091e+12\n1          1.560051e+12\n2          1.560089e+12\n3          1.560063e+12\n4          1.560079e+12\n               ...     \n1099995    1.560166e+12\n1099996    1.560169e+12\n1099997    1.560123e+12\n1099998    1.560159e+12\n1099999    1.560106e+12\nName: nginxtime, Length: 1100000, dtype: float64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 本题所给时间戳为毫秒级，故需除以1000转换为秒级：时间戳转成日期格式\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(data['nginxtime'][0] / 1000)))\n",
    "\n",
    "# 对object类型的字段进行标签编码：\n",
    "for col in object_cols:\n",
    "    if col != 'sid':\n",
    "        data[col] = one_hot_col(data[col].astype(str)).transform(data[col].astype(str))\n",
    "\n",
    "print(data['nginxtime'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fold: 1 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[400]\tvalid_0's auc: 0.984056\n",
      "[800]\tvalid_0's auc: 0.98484\n",
      "[1200]\tvalid_0's auc: 0.985024\n",
      "[1600]\tvalid_0's auc: 0.985059\n",
      "Early stopping, best iteration is:\n[1746]\tvalid_0's auc: 0.985067\n",
      "fold: 2 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[400]\tvalid_0's auc: 0.983201\n",
      "[800]\tvalid_0's auc: 0.984107\n",
      "[1200]\tvalid_0's auc: 0.984285\n",
      "[1600]\tvalid_0's auc: 0.984314\n",
      "Early stopping, best iteration is:\n[1639]\tvalid_0's auc: 0.984321\n",
      "fold: 3 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[400]\tvalid_0's auc: 0.983511\n",
      "[800]\tvalid_0's auc: 0.98431\n",
      "[1200]\tvalid_0's auc: 0.984512\n",
      "[1600]\tvalid_0's auc: 0.984532\n",
      "Early stopping, best iteration is:\n[1431]\tvalid_0's auc: 0.984536\n",
      "fold: 4 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[400]\tvalid_0's auc: 0.983389\n",
      "[800]\tvalid_0's auc: 0.984193\n",
      "[1200]\tvalid_0's auc: 0.984354\n",
      "[1600]\tvalid_0's auc: 0.984403\n",
      "[2000]\tvalid_0's auc: 0.984406\n",
      "Early stopping, best iteration is:\n[1855]\tvalid_0's auc: 0.984416\n",
      "fold: 5 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[400]\tvalid_0's auc: 0.983352\n",
      "[800]\tvalid_0's auc: 0.984152\n",
      "[1200]\tvalid_0's auc: 0.984331\n",
      "[1600]\tvalid_0's auc: 0.984369\n",
      "Early stopping, best iteration is:\n[1609]\tvalid_0's auc: 0.98437\n",
      "the roc_auc_score for train: 0.9845374516450558\ntest pre_label distribution:\n 1    50014\n0    49986\nName: label, dtype: int64\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  from ipykernel import kernelapp as app\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 划分数据：\n",
    "train = data[:traindata.shape[0]]\n",
    "label = train['label'].values\n",
    "test = data[traindata.shape[0]:].reset_index(drop=True)\n",
    "\n",
    "# 模型训练预测：\n",
    "oof_lgb, prediction_lgb, feature_importance_df = \\\n",
    "    lgb_model(np.array(train.drop(['sid', 'label', 'nginxtime', 'ip', 'reqrealip', 'begintime'], axis=1)),\n",
    "              label,\n",
    "              np.array(test.drop(['sid', 'label', 'nginxtime', 'ip', 'reqrealip', 'begintime'], axis=1)))\n",
    "\n",
    "# 保存结果：\n",
    "sub = test[['sid']]\n",
    "sub['label'] = prediction_lgb\n",
    "sub['label'] = sub['label'].apply(lambda x: 1 if x > 0.5 else 0)  # ∪概率大于0.5的置1，否则置0\n",
    "print('test pre_label distribution:\\n', sub['label'].value_counts())  # 模型预测测试集的标签分布\n",
    "sub.to_csv('submit0704.csv', index=None)  # 保存为submit0704.csv文件\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-e50da876",
   "language": "python",
   "display_name": "PyCharm (ForecastScore)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}